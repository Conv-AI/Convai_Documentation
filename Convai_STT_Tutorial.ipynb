{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Conv-AI/Convai_Documentation/blob/main/Convai_STT_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convai STT API Tutorial\n",
        "\n",
        "This interactive python notebook consists of code snippets that illustrates the different API endpoints related to speech-to-text services provided by Convai.\n",
        "\n",
        "In the notebook, we will only deal with offline-transcription, where you can generate transcript by uploading an audio file.\n",
        "\n",
        "\n",
        "Note:\n",
        "1. Before moving on with this tutorial, remember to get your API-Key from the profile section.\n",
        "2. Upload some sample audio file, in the colab, to generate a transcript for.\n",
        "3. Convai support audio transcript generation for **wav** and **mp3** formats only.\n",
        "\n",
        "You can always refer to the documentation here for more details: [Link](https://docs.convai.com/api-docs/reference/api-reference/speech-to-text-api)"
      ],
      "metadata": {
        "id": "ATg_dM-wA0VA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "W8lhE--tUl50"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jhL63bOa9bA4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up API key"
      ],
      "metadata": {
        "id": "K4U2F1JEUssl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CONVAI_API_KEY\"]= \"your-api-key\""
      ],
      "metadata": {
        "id": "-WiCm9LiUpxU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Offline STT Call\n",
        "\n",
        "This a pretty simple request made to the endpoint to get back the transcript. \n",
        "\n",
        "We can decide to get back only the transcript of the audio or more details with timestamps of particular sections of the transcript, by setting the **enableTimestamp** attribute value in the request."
      ],
      "metadata": {
        "id": "aF8F3aREUvXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STT_URL = \"https://api.convai.com/stt/\"\n",
        "TIMESTAMP_REQUIRED_FLAG = \"True\"\n",
        "\n",
        "payload={\n",
        "\t\"enableTimestamps\": TIMESTAMP_REQUIRED_FLAG\t# Dont need to set if False (default).\n",
        "}\n",
        "\n",
        "files = {\n",
        "    \"file\": open('path-to-audio','rb'),\n",
        "}\n",
        "headers = {\n",
        "  \"CONVAI-API-KEY\": os.getenv(\"CONVAI_API_KEY\"),\n",
        "}\n",
        "\n",
        "response = requests.request(\"POST\", STT_URL, headers=headers, data=payload, files=files)\n",
        "\n",
        "if response.status_code == 200:\n",
        "  print(\"Transcript generated successfully\")\n",
        "\n",
        "  data = response.json()\n",
        "  print(\"Complete Transcript: \", data[\"result\"])\n",
        "\n",
        "  if TIMESTAMP_REQUIRED_FLAG:   # We print the details if only we have opted for generating timestamps\n",
        "    print(data[\"details\"])\n",
        "\n",
        "else:\n",
        "  print(\"Failed to generate transcript\")\n",
        "\n",
        "  data = response.json()\n",
        "  print(\"Error: \", data[\"ERROR\"])"
      ],
      "metadata": {
        "id": "1txu6KyFXdnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ac1dce93-c563-4bac-db24-9a06803e219c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript generated successfully\n",
            "Complete Transcript:  Ayon asked me to say puzzle, so I told Fuzz. \n",
            "[{'id': '1', 'start-time': '0:00:00,720', 'end-time': '0:00:03,839', 'text': 'Ayon asked me to say puzzle, so I told Fuzz. '}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The endpoint support processing of audio files on **wav** and **mp3** format only for now. We will extend our support to other formats pretty soon. If you have any dount or particular requirement to this, please reach out to our [Support Team](support@convai.com)."
      ],
      "metadata": {
        "id": "dUzytnXNZVZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add New Words\n",
        "\n",
        "You also have the ability to add new words to the vocabulary of the text corpus whenever you want to focus on the pronunciation of the new words.\n",
        "\n",
        "The following code carries out the task for adding new words. Say we want to add the word **\"convai\"** to our list."
      ],
      "metadata": {
        "id": "KLWt1f3CZu4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STT_ADD_WORD_URL = \"https://api.convai.com/stt/add-words\"\n",
        "\n",
        "payload = json.dumps({\n",
        "  \"word\": \"convai\"\n",
        "})\n",
        "headers = {\n",
        "  \"CONVAI-API-KEY\": os.getenv(\"CONVAI_API_KEY\"),\n",
        "  \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.request(\"POST\", STT_ADD_WORD_URL, headers=headers, data=payload)\n",
        "\n",
        "if response.status_code == 200:\n",
        "  print(\"New word added\")\n",
        "\n",
        "  data = response.json()\n",
        "  print(\"Status: \", data[\"STATUS\"])\n",
        "\n",
        "\n",
        "else:\n",
        "  print(\"Failed to add words\")\n",
        "\n",
        "  data = response.json()\n",
        "  print(\"Error: \", data[\"ERROR\"])"
      ],
      "metadata": {
        "id": "kbterglGZuZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e820580c-c259-491b-9b6c-77fc4b845c7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New word added\n",
            "Status:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that wraps up the basic tutorial on the Speech-To-Text service provided by Convai."
      ],
      "metadata": {
        "id": "dbGZt1wdaYdi"
      }
    }
  ]
}
